{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: OTRL\n",
    "### Author: Xinyuan Yan\n",
    "### xinyuanyan2016@gmail.com\n",
    "**April, 2021**\n",
    "\n",
    "**Main reference** \n",
    "\n",
    "1. Fontanesi, L., Gluth, S., Spektor, M. S., & Rieskamp, J. (2019). A reinforcement learning diffusion decision model for value-based decisions. Psychonomic bulletin & review, 26(4), 1099-1121.\n",
    "2. Wiehler, A., & Peters, J. (2020). Diffusion modeling reveals reinforcement learning impairments in gambling disorder that are linked to attenuated ventromedial prefrontal cortex value representations. bioRxiv.\n",
    "\n",
    "Edited code from rlssm key functions. \n",
    "\n",
    "Code is created and adapted by Xinyuan Yan, will be shared at her github website:\n",
    "https://github.com/psywalkeryanxy\n",
    "\n",
    "If you have any further questions, please email to me(xinyuanyan2016@gmail.com), I will provide help as much as I can ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this dataset\n",
    "**Between-subject design** \n",
    "\n",
    "**N(oxytocin) = **\n",
    "\n",
    "**N(placebo)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset can be download here:\n",
    "**Xinyuan, please provide the download link here later with Dr.Ma's permission**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean / Quality control declaration\n",
    "\n",
    "1. Discarding participants who did pass the accuray threshold\n",
    "**since an accuracy above 56% across 225 trials**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Participants were discarded in OT group, REWARD condition**\n",
    "\n",
    "'sub42yangjian'ACC_stable1 = 0.387755102\n",
    "\n",
    "'sub65lihao'ACC_stable1 =0.5\n",
    "\n",
    "'RL_sub1317_XQ_data-E-post'ACC_stable1 =0.4\n",
    "\n",
    "'RL_sub1335_SXY_data'ACC_stable1 =0.38\n",
    "\n",
    "**Participants were discarded in PL group, REWARD condition**\n",
    "\n",
    "'sub39zhaozijie'ACC_stable1 =0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools\n",
    "#import pystan, for parameter estimation\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_data = \"\"\"\n",
    "data {\n",
    "\tint<lower=1> N;\t\t\t\t\t\t\t\t\t// number of data items\n",
    "\tint<lower=1> K;\t\t\t\t\t\t\t\t\t// number of options\n",
    "\tint<lower=1> L;\t\t\t\t\t\t\t\t\t// number of levels\n",
    "\tint<lower=1, upper=L> participant[N];\t\t\t// level (participant)\n",
    "\tint<lower=1> trial_block[N];\t\t\t\t\t// trial within block\n",
    "\tvector[N] f_cor;\t\t\t\t\t\t\t\t// feedback correct option\n",
    "\tvector[N] f_inc;\t\t\t\t\t\t\t\t// feedback incorrect option\n",
    "\tint<lower=1, upper=K> cor_option[N];\t\t\t// correct option\n",
    "\tint<lower=1, upper=K> inc_option[N];\t\t\t// incorrect option\n",
    "\tint<lower=1> block_label[N];\t\t\t\t\t// block label\n",
    "\n",
    "\tint<lower=-1,upper=1> accuracy[N];\t\t\t\t// accuracy (-1, 1)\n",
    "\treal<lower=0> rt[N];\t\t\t\t\t\t\t// rt\n",
    "\n",
    "\treal initial_value;\t\t\t\t\t\t\t\t// intial value for learning in the first block\n",
    "\n",
    "\tvector[4] alpha_priors;\t\t\t\t\t\t\t// mean and sd of the prior\n",
    "\tvector[4] drift_scaling_priors;\t\t\t\t\t// mean and sd of the prior\n",
    "\tvector[4] threshold_priors;\t\t\t\t\t\t// mean and sd of the prior\n",
    "\tvector[4] ndt_priors;\t\t\t\t\t\t\t// mean and sd of the prior\n",
    "\treal<lower=0, upper=1> starting_point;\t\t\t// starting point diffusion model not to estimate\n",
    "}\n",
    "transformed data {\n",
    "\tvector[K] Q0;\n",
    "\tQ0 = rep_vector(initial_value, K);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_parameters = \"\"\"\n",
    "parameters {\n",
    "\treal mu_alpha;\n",
    "\treal mu_drift_scaling;\n",
    "\treal mu_threshold;\n",
    "\treal mu_ndt;\n",
    "\n",
    "\treal<lower=0> sd_alpha;\n",
    "\treal<lower=0> sd_drift_scaling;\n",
    "\treal<lower=0> sd_threshold;\n",
    "\treal<lower=0> sd_ndt;\n",
    "\n",
    "\treal z_alpha[L];\n",
    "\treal z_drift_scaling[L];\n",
    "\treal z_threshold[L];\n",
    "\treal z_ndt[L];\n",
    "}\n",
    "transformed parameters {\n",
    "\treal drift_ll[N];\t\t\t\t\t\t\t\t// trial-by-trial drift rate for likelihood (incorporates accuracy)\n",
    "\treal drift_t[N];\t\t\t\t\t\t\t\t// trial-by-trial drift rate for predictions\n",
    "\treal<lower=0> threshold_t[N];\t\t\t\t\t// trial-by-trial threshold\n",
    "\treal<lower=0> ndt_t[N];\t\t\t\t\t\t\t// trial-by-trial ndt\n",
    "\n",
    "\tvector[K] Q;\t\t\t\t\t\t\t\t\t// Q state values\n",
    "\n",
    "\treal Q_mean;\t\t\t\t\t\t\t\t\t// mean across all options\n",
    "\treal Q_mean_pres[N];\t\t\t\t\t\t\t// mean Q presented options\n",
    "\treal delta_Q[N];\t\t\t\t\t\t\t\t// Qcor - Qinc\n",
    "\treal PE_cor;\t\t\t\t\t\t\t\t\t// predicion error correct option\n",
    "\treal PE_inc;\t\t\t\t\t\t\t\t\t// predicion error incorrect option\n",
    "\n",
    "\treal<lower=0, upper=1> alpha_sbj[L];\n",
    "\treal<lower=0> drift_scaling_sbj[L];\n",
    "\treal<lower=0> threshold_sbj[L];\n",
    "\treal<lower=0> ndt_sbj[L];\n",
    "\n",
    "\treal transf_mu_alpha;\n",
    "\treal transf_mu_drift_scaling;\n",
    "\treal transf_mu_threshold;\n",
    "\treal transf_mu_ndt;\n",
    "\n",
    "\ttransf_mu_alpha = Phi(mu_alpha);\t\t\t\t// for the output\n",
    "\ttransf_mu_drift_scaling = log(1 + exp(mu_drift_scaling));\n",
    "\ttransf_mu_threshold = log(1 + exp(mu_threshold));\n",
    "\ttransf_mu_ndt = log(1 + exp(mu_ndt));\n",
    "\n",
    "\tfor (l in 1:L) {\n",
    "\t\talpha_sbj[l] = Phi(mu_alpha + z_alpha[l]*sd_alpha);\n",
    "\t\tdrift_scaling_sbj[l] = log(1 + exp(mu_drift_scaling + z_drift_scaling[l]*sd_drift_scaling));\n",
    "\t\tthreshold_sbj[l] = log(1 + exp(mu_threshold + z_threshold[l]*sd_threshold));\n",
    "\t\tndt_sbj[l] = log(1 + exp(mu_ndt + z_ndt[l]*sd_ndt));\n",
    "\t}\n",
    "\n",
    "\tfor (n in 1:N) {\n",
    "\t\tif (trial_block[n] == 1) {\n",
    "\t\t\tif (block_label[n] == 1) {\n",
    "\t\t\t\tQ = Q0;\n",
    "\t\t\t} else {\n",
    "\t\t\t\tQ_mean = mean(Q);\n",
    "\t\t\t\tQ = rep_vector(Q_mean, K);\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\tQ_mean_pres[n] = (Q[cor_option[n]] + Q[inc_option[n]])/2;\n",
    "\t\tdelta_Q[n] = Q[cor_option[n]] - Q[inc_option[n]];\n",
    "\t\tPE_cor = f_cor[n] - Q[cor_option[n]];\n",
    "\t\tPE_inc = f_inc[n] - Q[inc_option[n]];\n",
    "\n",
    "\t\tdrift_t[n] = drift_scaling_sbj[participant[n]]*delta_Q[n];\n",
    "\t\tdrift_ll[n] = drift_t[n]*accuracy[n];\n",
    "\t\tthreshold_t[n] = threshold_sbj[participant[n]];\n",
    "\t\tndt_t[n] = ndt_sbj[participant[n]];\n",
    "\n",
    "\t\tQ[cor_option[n]] = Q[cor_option[n]] + alpha_sbj[participant[n]]*PE_cor;\n",
    "\t\tQ[inc_option[n]] = Q[inc_option[n]] + alpha_sbj[participant[n]]*PE_inc;\n",
    "\t}\n",
    "} \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_model = \"\"\"\n",
    "model {\n",
    "\tmu_alpha ~ normal(alpha_priors[1], alpha_priors[2]);\n",
    "\tmu_drift_scaling ~ normal(drift_scaling_priors[1], drift_scaling_priors[2]);\n",
    "\tmu_threshold ~ normal(threshold_priors[1], threshold_priors[2]);\n",
    "\tmu_ndt ~ normal(ndt_priors[1], ndt_priors[2]);\n",
    "\n",
    "\tsd_alpha ~ normal(alpha_priors[3], alpha_priors[4]);\n",
    "\tsd_drift_scaling ~ normal(drift_scaling_priors[3], drift_scaling_priors[4]);\n",
    "\tsd_threshold ~ normal(threshold_priors[3], threshold_priors[4]);\n",
    "\tsd_ndt ~ normal(ndt_priors[3], ndt_priors[4]);\n",
    "\n",
    "\tz_alpha ~ normal(0, 1);\n",
    "\tz_drift_scaling ~ normal(0, 1);\n",
    "\tz_threshold ~ normal(0, 1);\n",
    "\tz_ndt ~ normal(0, 1);\n",
    "\n",
    "\trt ~ wiener(threshold_t, ndt_t, starting_point, drift_ll);\n",
    "}\n",
    "generated quantities {\n",
    "\tvector[N] log_lik;\n",
    "\n",
    "\t{for (n in 1:N) {\n",
    "\t\tlog_lik[n] = wiener_lpdf(rt[n] | threshold_t[n], ndt_t[n], starting_point, drift_ll[n]);\n",
    "\t}\n",
    "\t}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sampling methods in PyStan require the data to be input as a Python dictionary whose keys match\n",
    "#the data block of the Stan code.\n",
    "\n",
    "\n",
    "data = pd.read_csv('data_OT_REWARD_200.csv')\n",
    "model_label = 'hierRLDDM'#####PLEASE PAY ATTENTION!!!!\n",
    "# learning parameters\n",
    "N = data.shape[0] # n observations\n",
    "K = 2 # n options in a learning block (participants see 2 at a time)\n",
    "L = len(pd.unique(data.participant)) \n",
    "\n",
    "initial_value_learning = 0.5 # intitial learning value (Q0)\n",
    "\n",
    "alpha_priors={'mu_mu':0, 'sd_mu':1, 'mu_sd':0, 'sd_sd':.1}\n",
    "\n",
    "drift_scaling_priors={'mu_mu':1, 'sd_mu':30, 'mu_sd':0, 'sd_sd':30}\n",
    "\n",
    "threshold_priors={'mu_mu':1, 'sd_mu':3, 'mu_sd':0, 'sd_sd':3}\n",
    "\n",
    "ndt_priors={'mu_mu':1, 'sd_mu':1, 'mu_sd':0, 'sd_sd':1}\n",
    "\n",
    "# transform data variables\n",
    "data['accuracy_neg'] = -1\n",
    "data.loc[data.accuracy == 1, 'accuracy_neg'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>block_label</th>\n",
       "      <th>trial_block</th>\n",
       "      <th>f_cor</th>\n",
       "      <th>f_inc</th>\n",
       "      <th>cor_option</th>\n",
       "      <th>inc_option</th>\n",
       "      <th>times_seen</th>\n",
       "      <th>rt</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.427829</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.849174</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.749040</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.596714</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11230</th>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>0.494948</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11231</th>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "      <td>0.411379</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232</th>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>223</td>\n",
       "      <td>0.330851</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11233</th>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>0.812914</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11234</th>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>0.660816</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11235 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       participant  block_label  trial_block  f_cor  f_inc  cor_option  \\\n",
       "0                1            1            1      1      0           2   \n",
       "1                1            1            2      1      0           1   \n",
       "2                1            1            3      1      0           1   \n",
       "3                1            1            4      1      0           2   \n",
       "4                1            1            5      1      0           2   \n",
       "...            ...          ...          ...    ...    ...         ...   \n",
       "11230           51            7           46      1      0           2   \n",
       "11231           51            7           47      1      0           1   \n",
       "11232           51            7           48      1      0           1   \n",
       "11233           51            7           49      1      0           2   \n",
       "11234           51            7           50      1      0           1   \n",
       "\n",
       "       inc_option  times_seen        rt  accuracy  accuracy_neg  \n",
       "0               1           1  1.427829         0            -1  \n",
       "1               2           2  0.849174         0            -1  \n",
       "2               2           3  1.749040         1             1  \n",
       "3               1           4  0.806818         0            -1  \n",
       "4               1           5  1.596714         1             1  \n",
       "...           ...         ...       ...       ...           ...  \n",
       "11230           1         221  0.494948         1             1  \n",
       "11231           2         222  0.411379         0            -1  \n",
       "11232           2         223  0.330851         0            -1  \n",
       "11233           1         224  0.812914         0            -1  \n",
       "11234           2         225  0.660816         1             1  \n",
       "\n",
       "[11235 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data #view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define priors\n",
    "priors = dict(\n",
    "                alpha_priors={'mu_mu':0, 'sd_mu':1, 'mu_sd':0, 'sd_sd':.1},\n",
    "                alpha_pos_priors={'mu_mu':0, 'sd_mu':1, 'mu_sd':0, 'sd_sd':.1},\n",
    "                alpha_neg_priors={'mu_mu':0, 'sd_mu':1, 'mu_sd':0, 'sd_sd':.1},\n",
    "                drift_scaling_priors={'mu_mu':1, 'sd_mu':30, 'mu_sd':0, 'sd_sd':30},\n",
    "                drift_asymptote_priors={'mu_mu':1, 'sd_mu':30, 'mu_sd':0, 'sd_sd':30},\n",
    "                threshold_priors={'mu_mu':1, 'sd_mu':3, 'mu_sd':0, 'sd_sd':3},\n",
    "                threshold_modulation_priors={'mu_mu':0, 'sd_mu':10, 'mu_sd':0, 'sd_sd':10},\n",
    "                ndt_priors={'mu_mu':1, 'sd_mu':1, 'mu_sd':0, 'sd_sd':1}\n",
    "                )\n",
    "priors['alpha_priors'] = alpha_priors\n",
    "priors['drift_scaling_priors'] = drift_scaling_priors\n",
    "priors['threshold_priors'] = threshold_priors\n",
    "#priors['threshold_modulation_priors'] = threshold_modulation_priors\n",
    "priors['ndt_priors'] = ndt_priors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_bc4dd4dced0824789d173a170c757d92 NOW.\n"
     ]
    },
    {
     "ename": "LinkError",
     "evalue": "command 'x86_64-apple-darwin13.4.0-clang++' failed with exit status 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDistutilsExecError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/unixccompiler.py\u001b[0m in \u001b[0;36mlink\u001b[0;34m(self, target_desc, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinker\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mld_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDistutilsExecError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/ccompiler.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cmd, search_path, verbose, dry_run)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'posix'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0m_spawn_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/spawn.py\u001b[0m in \u001b[0;36m_spawn_posix\u001b[0;34m(cmd, search_path, verbose, dry_run)\u001b[0m\n\u001b[1;32m    158\u001b[0m                           \u001b[0;34m\"command %r failed with exit status %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                           % (cmd, exit_status))\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWIFSTOPPED\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDistutilsExecError\u001b[0m: command 'x86_64-apple-darwin13.4.0-clang++' failed with exit status 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLinkError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7aafb74ebc85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStanModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooled_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpooled_parameters\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpooled_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#define data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m data_dict = {'N': N,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/site-packages/pystan/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, charset, model_name, model_code, stanc_ret, include_paths, boost_lib, eigen_lib, verbose, obfuscate_model_name, extra_compile_args, allow_undefined, include_dirs, includes)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mbuild_extension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mredirect_stderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/command/build_ext.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;31m# Now actually compile and link everything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_extensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_extensions_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/command/build_ext.py\u001b[0m in \u001b[0;36mbuild_extensions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_extensions_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_extensions_serial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_extensions_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/command/build_ext.py\u001b[0m in \u001b[0;36m_build_extensions_serial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_build_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/command/build_ext.py\u001b[0m in \u001b[0;36mbuild_extension\u001b[0;34m(self, ext)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mbuild_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_temp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             target_lang=language)\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mswig_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/ccompiler.py\u001b[0m in \u001b[0;36mlink_shared_object\u001b[0;34m(self, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)\u001b[0m\n\u001b[1;32m    715\u001b[0m                   \u001b[0mlibraries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibrary_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime_library_dirs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                   \u001b[0mexport_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                   extra_preargs, extra_postargs, build_temp, target_lang)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stanenv/lib/python3.7/distutils/unixccompiler.py\u001b[0m in \u001b[0;36mlink\u001b[0;34m(self, target_desc, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinker\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mld_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDistutilsExecError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mLinkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skipping %s (up-to-date)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinkError\u001b[0m: command 'x86_64-apple-darwin13.4.0-clang++' failed with exit status 1"
     ]
    }
   ],
   "source": [
    "sm = pystan.StanModel(model_code=pooled_data + pooled_parameters + pooled_model)\n",
    "\n",
    "#define data\n",
    "\n",
    "data_dict = {'N': N,\n",
    "             'K': K,\n",
    "             'L': L,\n",
    "             'participant': data['participant'].values.astype(int),\n",
    "             'trial_block': data['trial_block'].values.astype(int),\n",
    "             'f_cor': data['f_cor'].values,\n",
    "             'f_inc': data['f_inc'].values,\n",
    "             'cor_option': data['cor_option'].values.astype(int),\n",
    "             'inc_option': data['inc_option'].values.astype(int),\n",
    "             'block_label': data['block_label'].values.astype(int),\n",
    "             'rt': data['rt'].values,\n",
    "             'accuracy': data['accuracy_neg'].values.astype(int),\n",
    "             'initial_value': initial_value_learning,\n",
    "             'alpha_priors':[0,1,0,0.1],\n",
    "             'drift_scaling_priors':[1,3,0,3],\n",
    "             'threshold_priors':[1,3,0,3],\n",
    "             'ndt_priors':[1,1,0,1],\n",
    "             'starting_point': .5}\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "fit = sm.sampling(data_dict,iter=1000, chains=2,n_jobs=2\n",
    "                 )\n",
    "\n",
    "#print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_eff': False,\n",
       " 'Rhat': False,\n",
       " 'divergence': True,\n",
       " 'treedepth': True,\n",
       " 'energy': True}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pystan.check_hmc_diagnostics(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglik = fit['log_lik']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predictive check analysis preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "## pure DDM\n",
    "def random_ddm(drift, threshold, ndt, rel_sp=.5, noise_constant=1, dt=0.001, max_rt=10):\n",
    "    \"\"\"Simulates behavior (rt and accuracy) according to the diffusion decision model.\n",
    "\n",
    "    In this parametrization, it is assumed that 0 is the lower threshold,\n",
    "    and, when rel_sp=1/2, the diffusion process starts halfway through the threshold value.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "\n",
    "    This function is mainly for the posterior predictive calculations.\n",
    "    It assumes that drift, threshold and ndt are provided as numpy.ndarray\n",
    "    of shape (n_samples, n_trials).\n",
    "\n",
    "    However, it also works when the rel_sp is given as a float.\n",
    "    Drift, threshold and ndt should have the same shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    drift : numpy.ndarray\n",
    "        Shape is usually (n_samples, n_trials).\n",
    "        Drift-rate of the diffusion decision model.\n",
    "\n",
    "    threshold : numpy.ndarray\n",
    "        Shape is usually (n_samples, n_trials).\n",
    "        Threshold of the diffusion decision model.\n",
    "\n",
    "    ndt : numpy.ndarray\n",
    "        Shape is usually (n_samples, n_trials).\n",
    "        Non decision time of the diffusion decision model, in seconds.\n",
    "\n",
    "    Other Parameters\n",
    "    ----------------\n",
    "\n",
    "    rel_sp : numpy.ndarray or float, default .5\n",
    "        When is an array , shape is usually (n_samples, n_trials).\n",
    "        Relative starting point of the diffusion decision model.\n",
    "\n",
    "    noise_constant : float, default 1\n",
    "        Scaling factor of the diffusion decision model.\n",
    "        If changed, drift and threshold would be scaled accordingly.\n",
    "        Not to be changed in most applications.\n",
    "\n",
    "    max_rt : float, default 10\n",
    "        Controls the maximum rts that can be predicted.\n",
    "        Making this higher might make the function a bit slower.\n",
    "\n",
    "    dt : float, default 0.001\n",
    "        Controls the time resolution of the diffusion decision model. Default is 1 msec.\n",
    "        Lower values of dt make the function more precise but much slower.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    rt : numpy.ndarray\n",
    "        Shape is the same as the input parameters.\n",
    "        Contains simulated response times according to the diffusion decision model.\n",
    "        Every element corresponds to the set of parameters given as input with the same shape.\n",
    "\n",
    "    acc: numpy.ndarray\n",
    "        Shape is the same as the input parameters.\n",
    "        Contains simulated accuracy according to the diffusion decision model.\n",
    "        Every element corresponds to the set of parameters given as input with the same shape.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    shape = drift.shape\n",
    "\n",
    "    acc = np.empty(shape)\n",
    "    acc[:] = np.nan\n",
    "    rt = np.empty(shape)\n",
    "    rt[:] = np.nan\n",
    "    rel_sp = np.ones(shape)*rel_sp\n",
    "    max_tsteps = max_rt/dt\n",
    "\n",
    "    # initialize the diffusion process\n",
    "    x = np.ones(shape)*rel_sp*threshold\n",
    "    tstep = 0\n",
    "    ongoing = np.array(np.ones(shape), dtype=bool)\n",
    "\n",
    "    # start accumulation process\n",
    "    while np.sum(ongoing) > 0 and tstep < max_tsteps:\n",
    "        x[ongoing] += np.random.normal(drift[ongoing]*dt,\n",
    "                                       noise_constant*np.sqrt(dt),\n",
    "                                       np.sum(ongoing))\n",
    "        tstep += 1\n",
    "\n",
    "        # ended trials\n",
    "        ended_correct = (x >= threshold)\n",
    "        ended_incorrect = (x <= 0)\n",
    "\n",
    "        # store results and filter out ended trials\n",
    "        if np.sum(ended_correct) > 0:\n",
    "            acc[np.logical_and(ended_correct, ongoing)] = 1\n",
    "            rt[np.logical_and(ended_correct, ongoing)] = dt*tstep + ndt[np.logical_and(ended_correct,\n",
    "                                                                                       ongoing)]\n",
    "            ongoing[ended_correct] = False\n",
    "\n",
    "        if np.sum(ended_incorrect) > 0:\n",
    "            acc[np.logical_and(ended_incorrect, ongoing)] = 0\n",
    "            rt[np.logical_and(ended_incorrect, ongoing)] = dt*tstep + ndt[np.logical_and(ended_incorrect,\n",
    "                                                                                         ongoing)]\n",
    "            ongoing[ended_incorrect] = False\n",
    "\n",
    "    return rt, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check all diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rlssm\n",
    "from rlssm import stan_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_eff / iter looks reasonable for all parameters\n"
     ]
    }
   ],
   "source": [
    "stan_utility.check_n_eff(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checks MCMC diagnostics:\n",
      "n_eff / iter looks reasonable for all parameters\n",
      "0.0 of 1000 iterations ended with a divergence (0.0%)\n",
      "0 of 1000 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "E-BFMI indicated no pathological behavior\n"
     ]
    }
   ],
   "source": [
    "stan_utility.check_all_diagnostics(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlssm import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_params = fit.get_sampler_params(inc_warmup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "import pickle\n",
    "from math import isnan\n",
    "from math import isinf\n",
    "from hashlib import md5\n",
    "import pystan\n",
    "import numpy\n",
    "\n",
    "def check_div(fit):\n",
    "    \"\"\"Check transitions that ended with a divergence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    fit : pystan.StanFit4model\n",
    "        The fitted stan model.\n",
    "\n",
    "    \"\"\"\n",
    "    sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "    divergent = [x for y in sampler_params for x in y['divergent__']]\n",
    "    n = sum(divergent)\n",
    "    N = len(divergent)\n",
    "    print('{} of {} iterations ended with a divergence ({}%)'.format(n, N, 100 * n / N))\n",
    "    if n > 0:\n",
    "        print('  Try running with larger adapt_delta to remove the divergences')\n",
    "\n",
    "def check_treedepth(fit, max_depth=10):\n",
    "    \"\"\"Check transitions that ended prematurely due to maximum tree depth limit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    fit : pystan.StanFit4model\n",
    "        The fitted stan model.\n",
    "\n",
    "    max_depth : int\n",
    "        Maximum tree depth.\n",
    "\n",
    "    \"\"\"\n",
    "    sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "    depths = [x for y in sampler_params for x in y['treedepth__']]\n",
    "    n = sum(1 for x in depths if x == max_depth)\n",
    "    N = len(depths)\n",
    "    print(('{} of {} iterations saturated the maximum tree depth of {}' +\n",
    "           ' ({}%)').format(n, N, max_depth, 100 * n / N))\n",
    "    if n > 0:\n",
    "        print('Run again with max_depth set to a larger value to avoid saturation')\n",
    "\n",
    "def check_energy(fit):\n",
    "    \"\"\"Checks the energy Bayesian fraction of missing information (E-BFMI).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    fit : pystan.StanFit4model\n",
    "        The fitted stan model.\n",
    "\n",
    "    \"\"\"\n",
    "    sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "    no_warning = True\n",
    "    for chain_num, s in enumerate(sampler_params):\n",
    "        energies = s['energy__']\n",
    "        numer = sum((energies[i] - energies[i - 1])**2 for i in range(1, len(energies))) / len(energies)\n",
    "        denom = numpy.var(energies)\n",
    "        if numer / denom < 0.2:\n",
    "            print('Chain {}: E-BFMI = {}'.format(chain_num, numer / denom))\n",
    "            no_warning = False\n",
    "    if no_warning:\n",
    "        print('E-BFMI indicated no pathological behavior')\n",
    "    else:\n",
    "        print('  E-BFMI below 0.2 indicates you may need to reparameterize your model')\n",
    "\n",
    "def check_n_eff(fit):\n",
    "    \"\"\"Checks the effective sample size per iteration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    fit : pystan.StanFit4model\n",
    "        The fitted stan model.\n",
    "\n",
    "    \"\"\"\n",
    "    fit_summary = fit.summary(probs=[0.5])\n",
    "    n_effs = [x[4] for x in fit_summary['summary']]\n",
    "    names = fit_summary['summary_rownames']\n",
    "    n_iter = len(fit.extract()['lp__'])\n",
    "\n",
    "    no_warning = True\n",
    "    for n_eff, name in zip(n_effs, names):\n",
    "        ratio = n_eff / n_iter\n",
    "        if ratio < 0.001:\n",
    "            print('n_eff / iter for parameter {} is {}!'.format(name, ratio))\n",
    "            print('E-BFMI below 0.2 indicates you may need to reparameterize your model')\n",
    "            no_warning = False\n",
    "    if no_warning:\n",
    "        print('n_eff / iter looks reasonable for all parameters')\n",
    "    else:\n",
    "        print('n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated')\n",
    "\n",
    "def check_rhat(fit):\n",
    "    \"\"\"Checks the potential scale reduction factors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    fit : pystan.StanFit4model\n",
    "        The fitted stan model.\n",
    "\n",
    "    \"\"\"\n",
    "    fit_summary = fit.summary(probs=[0.5])\n",
    "    rhats = [x[5] for x in fit_summary['summary']]\n",
    "    names = fit_summary['summary_rownames']\n",
    "\n",
    "    no_warning = True\n",
    "    for rhat, name in zip(rhats, names):\n",
    "        if (rhat > 1.01 or isnan(rhat) or isinf(rhat)):\n",
    "            print('Rhat for parameter {} is {}!'.format(name, rhat))\n",
    "            no_warning = False\n",
    "    if no_warning:\n",
    "        print('Rhat looks reasonable for all parameters')\n",
    "    else:\n",
    "        print('Rhat above 1.01 indicates that the chains very likely have not mixed')\n",
    "\n",
    "def check_all_diagnostics(fit):\n",
    "    \"\"\"Checks all MCMC diagnostics, apart from rhat convergence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    fit : pystan.StanFit4model\n",
    "        The fitted stan model.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Checks MCMC diagnostics:\")\n",
    "    check_n_eff(fit)\n",
    "    check_div(fit)\n",
    "    check_treedepth(fit)\n",
    "    check_energy(fit)\n",
    "\n",
    "def _by_chain(unpermuted_extraction):\n",
    "    num_chains = len(unpermuted_extraction[0])\n",
    "    result = [[] for _ in range(num_chains)]\n",
    "    for c in range(num_chains):\n",
    "        for i in range(len(unpermuted_extraction)):\n",
    "            result[c].append(unpermuted_extraction[i][c])\n",
    "    return numpy.array(result)\n",
    "\n",
    "def _shaped_ordered_params(fit):\n",
    "    # flattened, unpermuted, by (iteration, chain)\n",
    "    ef = fit.extract(permuted=False, inc_warmup=False)\n",
    "    ef = _by_chain(ef)\n",
    "    ef = ef.reshape(-1, len(ef[0][0]))\n",
    "    ef = ef[:, 0:len(fit.flatnames)] # drop lp__\n",
    "    shaped = {}\n",
    "    idx = 0\n",
    "    for dim, param_name in zip(fit.par_dims, fit.extract().keys()):\n",
    "        length = int(numpy.prod(dim))\n",
    "        shaped[param_name] = ef[:, idx:idx + length]\n",
    "        shaped[param_name].reshape(*([-1] + dim))\n",
    "        idx += length\n",
    "    return shaped\n",
    "\n",
    "def partition_div(fit):\n",
    "    \"\"\"Returns parameter arrays separated into divergent and non-divergent transitions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    fit : pystan.StanFit4model\n",
    "        The fitted stan model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    nondiv_params : dict\n",
    "        Dictionary containing the non-divergent transitions per parameter.\n",
    "\n",
    "    div_params : dict\n",
    "        Dictionary containing the divergent transitions per parameter.\n",
    "\n",
    "    \"\"\"\n",
    "    sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "    div = numpy.concatenate([x['divergent__'] for x in sampler_params]).astype('int')\n",
    "    params = _shaped_ordered_params(fit)\n",
    "    nondiv_params = dict((key, params[key][div == 0]) for key in params)\n",
    "    div_params = dict((key, params[key][div == 1]) for key in params)\n",
    "    return nondiv_params, div_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-BFMI indicated no pathological behavior\n"
     ]
    }
   ],
   "source": [
    "check_energy(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracts the last posterior estimates values in each chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlssm import fits_DDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_levels = 2\n",
    "\n",
    "family = 'RLDDM'\n",
    "n_parameters_individual = 5\n",
    "n_parameters_trial=0\n",
    "print_diagnostics =True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_DDM.DDMFittedModel.stan_model = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_DDM.DDMFittedModel.model_label = model_label\n",
    "fits_DDM.DDMFittedModel.family = family\n",
    "fits_DDM.DDMFittedModel.priors = priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting key paramter information for fitted DDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_DDM.DDMFittedModel.data_info = {'N': data.shape[0], 'data':data}\n",
    "\n",
    "n_samples_after_warmup = fits_DDM.DDMFittedModel.stan_model.stan_args[0]['iter'] - fits_DDM.DDMFittedModel.stan_model.stan_args[0]['warmup']\n",
    "n_posterior_samples = n_samples_after_warmup / fits_DDM.DDMFittedModel.stan_model.stan_args[0]['thin']*len(fits_DDM.DDMFittedModel.stan_model.stan_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_DDM.DDMFittedModel.parameters_info = {'hierarchical_levels': hierarchical_levels,\n",
    "                                'n_parameters_individual':n_parameters_individual,\n",
    "                                'n_parameters_trial': n_parameters_trial,\n",
    "                                'n_posterior_samples': int(n_posterior_samples)}\n",
    "\n",
    "\n",
    "fits_DDM.DDMFittedModel.data_info.update({'L': len(pd.unique(data.participant))})\n",
    "fits_DDM.DDMFittedModel.parameters_info.update({'n_parameters_group': n_parameters_individual*2,\n",
    "                                         'n_parameters_hierarchical': n_parameters_individual*2 + n_parameters_individual*fits_DDM.DDMFittedModel.data_info['L']})\n",
    "\n",
    "r = re.compile(\"transf_.+\")\n",
    "parameters_names_transf = list(filter(r.match, fits_DDM.DDMFittedModel.stan_model.flatnames))\n",
    "individual_parameters_names = [name[10:] for name in parameters_names_transf]\n",
    "\n",
    "r = re.compile(\"mu_.+\")\n",
    "group_parameters_mu = list(filter(r.match, fits_DDM.DDMFittedModel.stan_model.flatnames))\n",
    "r = re.compile(\"sd_.+\")\n",
    "group_parameters_sd = list(filter(r.match, fits_DDM.DDMFittedModel.stan_model.flatnames))\n",
    "\n",
    "group_parameters_names_transf = parameters_names_transf + group_parameters_sd # add transformed par names for plotting\n",
    "group_parameters_names = group_parameters_mu + group_parameters_sd\n",
    "\n",
    "r = re.compile(\"z_.+_trial.+\")\n",
    "trials_deviations = list(filter(r.match, fits_DDM.DDMFittedModel.stan_model.flatnames))\n",
    "\n",
    "r = re.compile(\"z_.+\")\n",
    "individual_deviations = list(filter(r.match, fits_DDM.DDMFittedModel.stan_model.flatnames))\n",
    "\n",
    "if len(trials_deviations) > 0:\n",
    "    [individual_deviations.remove(el) for el in trials_deviations]\n",
    "\n",
    "parameters_names = group_parameters_names + individual_deviations\n",
    "parameters_names_all = parameters_names + trials_deviations\n",
    "\n",
    "fits_DDM.DDMFittedModel.parameters_info.update({'parameters_names': parameters_names, # group parameters and individual deviations\n",
    "                                         'group_parameters_names': group_parameters_names, # group parameters\n",
    "                                         'individual_parameters_names': individual_parameters_names, # names of individual parameters\n",
    "                                         'group_parameters_names_transf': parameters_names_transf, # group parameters for plotting\n",
    "                                         'parameters_names_all': parameters_names_all}) # all parameters for the rhat calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates rhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhat(self):\n",
    "        \"\"\"Extracts rhat from stan model's summary as a pandas dataframe.\n",
    "        Only considers parameters (Not all variables specified in stan's model).\n",
    "        Note that, when DDM parameters are estimated at a trial level, these are included in the rhat stats.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        convergence: DataFrame\n",
    "            Data frame with rows the parameters and columns the rhat and variable names.\n",
    "\n",
    "        \"\"\"\n",
    "        summary = self.stan_model.summary(pars=self.parameters_info['parameters_names_all'])\n",
    "        convergence = pd.DataFrame({'rhat': np.array(summary['summary'])[:, 9],\n",
    "                                    'variable': summary['summary_rownames']})\n",
    "        return convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rhat</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999246</td>\n",
       "      <td>mu_alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.001892</td>\n",
       "      <td>mu_drift_scaling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000440</td>\n",
       "      <td>mu_threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.029144</td>\n",
       "      <td>mu_ndt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.003151</td>\n",
       "      <td>sd_alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.027241</td>\n",
       "      <td>z_ndt[22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.013099</td>\n",
       "      <td>z_ndt[23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1.025241</td>\n",
       "      <td>z_ndt[24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.021191</td>\n",
       "      <td>z_ndt[25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.022209</td>\n",
       "      <td>z_ndt[26]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rhat          variable\n",
       "0    0.999246          mu_alpha\n",
       "1    1.001892  mu_drift_scaling\n",
       "2    1.000440      mu_threshold\n",
       "3    1.029144            mu_ndt\n",
       "4    1.003151          sd_alpha\n",
       "..        ...               ...\n",
       "107  1.027241         z_ndt[22]\n",
       "108  1.013099         z_ndt[23]\n",
       "109  1.025241         z_ndt[24]\n",
       "110  1.021191         z_ndt[25]\n",
       "111  1.022209         z_ndt[26]\n",
       "\n",
       "[112 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rhat(fits_DDM.DDMFittedModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates the Watanabe-Akaike information criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def calculate_waic(self, pointwise=False):\n",
    "        \"\"\"Calculates the Watanabe-Akaike information criteria.\n",
    "\n",
    "        Calculates pWAIC1 and pWAIC2\n",
    "        according to http://www.stat.columbia.edu/~gelman/research/published/waic_understand3.pdf\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        pointwise : bool, default to False\n",
    "            By default, gives the averaged waic.\n",
    "            Set to True is you want additional waic per observation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        out: dict\n",
    "            Dictionary containing lppd (log pointwise predictive density),\n",
    "            p_waic, waic, waic_se (standard error of the waic), and\n",
    "            pointwise_waic (when `pointwise` is True).\n",
    "\n",
    "        \"\"\"\n",
    "        log_likelihood = self.stan_model['log_lik'] # n_samples X N observations\n",
    "        likelihood = np.exp(log_likelihood)\n",
    "\n",
    "        mean_l = np.mean(likelihood, axis=0) # N observations\n",
    "\n",
    "        pointwise_lppd = np.log(mean_l)\n",
    "        lppd = np.sum(pointwise_lppd)\n",
    "\n",
    "        pointwise_var_l = np.var(log_likelihood, axis=0) # N observations\n",
    "        var_l = np.sum(pointwise_var_l)\n",
    "\n",
    "        pointwise_waic = - 2*pointwise_lppd +  2*pointwise_var_l\n",
    "        waic = -2*lppd + 2*var_l\n",
    "        waic_se = np.sqrt(self.data_info['N'] * np.var(pointwise_waic))\n",
    "\n",
    "        if pointwise:\n",
    "            out = {'lppd':lppd,\n",
    "                   'p_waic':var_l,\n",
    "                   'waic':waic,\n",
    "                   'waic_se':waic_se,\n",
    "                   'pointwise_waic':pointwise_waic}\n",
    "        else:\n",
    "            out = {'lppd':lppd,\n",
    "                   'p_waic':var_l,\n",
    "                   'waic':waic,\n",
    "                   'waic_se':waic_se}\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lppd': -670.5569137050618,\n",
       " 'p_waic': 132.08899759798925,\n",
       " 'waic': 1605.291822606102,\n",
       " 'waic_se': 185.45244060567714}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_waic(fits_DDM.DDMFittedModel,pointwise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracts the last posterior estimates values in each chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_last_values(self):\n",
    "        \"\"\"Extracts the last posterior estimates values in each chain.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        starting_points: DataFrame\n",
    "             Data frame with as many rows as number of chains that were run.\n",
    "             Parameter values are in separate columns.\n",
    "\n",
    "        \"\"\"\n",
    "        samplesChains = self.stan_model.to_dataframe(pars=self.parameters_info['parameters_names_all'],\n",
    "                                                     permuted=False,\n",
    "                                                     diagnostics=False)\n",
    "        starting_points = samplesChains[samplesChains['draw'] == max(samplesChains['draw'])]\n",
    "\n",
    "        return starting_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain</th>\n",
       "      <th>draw</th>\n",
       "      <th>warmup</th>\n",
       "      <th>mu_alpha</th>\n",
       "      <th>mu_drift_scaling</th>\n",
       "      <th>mu_ndt</th>\n",
       "      <th>mu_threshold</th>\n",
       "      <th>sd_alpha</th>\n",
       "      <th>sd_drift_scaling</th>\n",
       "      <th>sd_ndt</th>\n",
       "      <th>...</th>\n",
       "      <th>z_threshold[25]</th>\n",
       "      <th>z_threshold[26]</th>\n",
       "      <th>z_threshold[2]</th>\n",
       "      <th>z_threshold[3]</th>\n",
       "      <th>z_threshold[4]</th>\n",
       "      <th>z_threshold[5]</th>\n",
       "      <th>z_threshold[6]</th>\n",
       "      <th>z_threshold[7]</th>\n",
       "      <th>z_threshold[8]</th>\n",
       "      <th>z_threshold[9]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.317821</td>\n",
       "      <td>2.400149</td>\n",
       "      <td>-1.314574</td>\n",
       "      <td>0.867637</td>\n",
       "      <td>0.516985</td>\n",
       "      <td>1.416206</td>\n",
       "      <td>0.228376</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.570970</td>\n",
       "      <td>-0.183566</td>\n",
       "      <td>0.886075</td>\n",
       "      <td>0.929276</td>\n",
       "      <td>3.376794</td>\n",
       "      <td>0.255745</td>\n",
       "      <td>0.823514</td>\n",
       "      <td>0.853557</td>\n",
       "      <td>0.238764</td>\n",
       "      <td>0.124827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.445689</td>\n",
       "      <td>1.485573</td>\n",
       "      <td>-1.218856</td>\n",
       "      <td>1.015932</td>\n",
       "      <td>0.454298</td>\n",
       "      <td>1.915648</td>\n",
       "      <td>0.185287</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.767645</td>\n",
       "      <td>-1.268477</td>\n",
       "      <td>0.100287</td>\n",
       "      <td>0.078073</td>\n",
       "      <td>2.370765</td>\n",
       "      <td>-0.417724</td>\n",
       "      <td>0.204523</td>\n",
       "      <td>0.590331</td>\n",
       "      <td>-0.545381</td>\n",
       "      <td>-0.244102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chain  draw  warmup  mu_alpha  mu_drift_scaling    mu_ndt  mu_threshold  \\\n",
       "499      0   499       0 -0.317821          2.400149 -1.314574      0.867637   \n",
       "999      1   499       0 -0.445689          1.485573 -1.218856      1.015932   \n",
       "\n",
       "     sd_alpha  sd_drift_scaling    sd_ndt  ...  z_threshold[25]  \\\n",
       "499  0.516985          1.416206  0.228376  ...        -1.570970   \n",
       "999  0.454298          1.915648  0.185287  ...        -1.767645   \n",
       "\n",
       "     z_threshold[26]  z_threshold[2]  z_threshold[3]  z_threshold[4]  \\\n",
       "499        -0.183566        0.886075        0.929276        3.376794   \n",
       "999        -1.268477        0.100287        0.078073        2.370765   \n",
       "\n",
       "     z_threshold[5]  z_threshold[6]  z_threshold[7]  z_threshold[8]  \\\n",
       "499        0.255745        0.823514        0.853557        0.238764   \n",
       "999       -0.417724        0.204523        0.590331       -0.545381   \n",
       "\n",
       "     z_threshold[9]  \n",
       "499        0.124827  \n",
       "999       -0.244102  \n",
       "\n",
       "[2 rows x 115 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_values(fits_DDM.DDMFittedModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rhat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-b7f024016f8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#fits_DDM.DDMFittedModel.parameters_info = parameters_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfits_DDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDDMFittedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfits_DDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDDMFittedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrhat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfits_DDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDDMFittedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfits_DDM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDDMFittedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rhat' is not defined"
     ]
    }
   ],
   "source": [
    "trial_samples = fit.extract(['drift_t', 'threshold_t', 'ndt_t'])\n",
    "samples = fit.to_dataframe()\n",
    "\n",
    "fits_DDM.DDMFittedModel.model_label = model_label\n",
    "#fits_DDM.DDMFittedModel.data_info = data_info\n",
    "#fits_DDM.DDMFittedModel.parameters_info = parameters_info\n",
    "fits_DDM.DDMFittedModel.priors = priors\n",
    "fits_DDM.DDMFittedModel.rhat = rhat\n",
    "fits_DDM.DDMFittedModel.waic = waic\n",
    "fits_DDM.DDMFittedModel.last_values = last_values\n",
    "fits_DDM.DDMFittedModel.samples = samples\n",
    "fits_DDM.DDMFittedModel.trial_samples = trial_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior predictive check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "## pure DDM\n",
    "def random_ddm(drift, threshold, ndt, rel_sp=.5, noise_constant=1, dt=0.001, max_rt=10):\n",
    "    \"\"\"Simulates behavior (rt and accuracy) according to the diffusion decision model.\n",
    "\n",
    "    In this parametrization, it is assumed that 0 is the lower threshold,\n",
    "    and, when rel_sp=1/2, the diffusion process starts halfway through the threshold value.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "\n",
    "    This function is mainly for the posterior predictive calculations.\n",
    "    It assumes that drift, threshold and ndt are provided as numpy.ndarray\n",
    "    of shape (n_samples, n_trials).\n",
    "\n",
    "    However, it also works when the rel_sp is given as a float.\n",
    "    Drift, threshold and ndt should have the same shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    drift : numpy.ndarray\n",
    "        Shape is usually (n_samples, n_trials).\n",
    "        Drift-rate of the diffusion decision model.\n",
    "\n",
    "    threshold : numpy.ndarray\n",
    "        Shape is usually (n_samples, n_trials).\n",
    "        Threshold of the diffusion decision model.\n",
    "\n",
    "    ndt : numpy.ndarray\n",
    "        Shape is usually (n_samples, n_trials).\n",
    "        Non decision time of the diffusion decision model, in seconds.\n",
    "\n",
    "    Other Parameters\n",
    "    ----------------\n",
    "\n",
    "    rel_sp : numpy.ndarray or float, default .5\n",
    "        When is an array , shape is usually (n_samples, n_trials).\n",
    "        Relative starting point of the diffusion decision model.\n",
    "\n",
    "    noise_constant : float, default 1\n",
    "        Scaling factor of the diffusion decision model.\n",
    "        If changed, drift and threshold would be scaled accordingly.\n",
    "        Not to be changed in most applications.\n",
    "\n",
    "    max_rt : float, default 10\n",
    "        Controls the maximum rts that can be predicted.\n",
    "        Making this higher might make the function a bit slower.\n",
    "\n",
    "    dt : float, default 0.001\n",
    "        Controls the time resolution of the diffusion decision model. Default is 1 msec.\n",
    "        Lower values of dt make the function more precise but much slower.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    rt : numpy.ndarray\n",
    "        Shape is the same as the input parameters.\n",
    "        Contains simulated response times according to the diffusion decision model.\n",
    "        Every element corresponds to the set of parameters given as input with the same shape.\n",
    "\n",
    "    acc: numpy.ndarray\n",
    "        Shape is the same as the input parameters.\n",
    "        Contains simulated accuracy according to the diffusion decision model.\n",
    "        Every element corresponds to the set of parameters given as input with the same shape.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    shape = drift.shape\n",
    "\n",
    "    acc = np.empty(shape)\n",
    "    acc[:] = np.nan\n",
    "    rt = np.empty(shape)\n",
    "    rt[:] = np.nan\n",
    "    rel_sp = np.ones(shape)*rel_sp\n",
    "    max_tsteps = max_rt/dt\n",
    "\n",
    "    # initialize the diffusion process\n",
    "    x = np.ones(shape)*rel_sp*threshold\n",
    "    tstep = 0\n",
    "    ongoing = np.array(np.ones(shape), dtype=bool)\n",
    "\n",
    "    # start accumulation process\n",
    "    while np.sum(ongoing) > 0 and tstep < max_tsteps:\n",
    "        x[ongoing] += np.random.normal(drift[ongoing]*dt,\n",
    "                                       noise_constant*np.sqrt(dt),\n",
    "                                       np.sum(ongoing))\n",
    "        tstep += 1\n",
    "\n",
    "        # ended trials\n",
    "        ended_correct = (x >= threshold)\n",
    "        ended_incorrect = (x <= 0)\n",
    "\n",
    "        # store results and filter out ended trials\n",
    "        if np.sum(ended_correct) > 0:\n",
    "            acc[np.logical_and(ended_correct, ongoing)] = 1\n",
    "            rt[np.logical_and(ended_correct, ongoing)] = dt*tstep + ndt[np.logical_and(ended_correct,\n",
    "                                                                                       ongoing)]\n",
    "            ongoing[ended_correct] = False\n",
    "\n",
    "        if np.sum(ended_incorrect) > 0:\n",
    "            acc[np.logical_and(ended_incorrect, ongoing)] = 0\n",
    "            rt[np.logical_and(ended_incorrect, ongoing)] = dt*tstep + ndt[np.logical_and(ended_incorrect,\n",
    "                                                                                         ongoing)]\n",
    "            ongoing[ended_incorrect] = False\n",
    "\n",
    "    return rt, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_posterior_predictives(self, n_posterior_predictives=500, **kwargs):\n",
    "        starting_point_bias = False\n",
    "        \"\"\"Calculates posterior predictives of choices and response times.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        n_posterior_predictives : int\n",
    "             Number of posterior samples to use for posterior predictives calculation.\n",
    "             If n_posterior_predictives is bigger than the posterior samples,\n",
    "             then calculation will continue with the total number of posterior samples.\n",
    "\n",
    "        Other Parameters\n",
    "        ----------------\n",
    "\n",
    "        noise_constant : float\n",
    "            Scaling factor of the diffusion decision model.\n",
    "            If changed, drift and threshold would be scaled accordingly.\n",
    "            Not to be changed in most applications.\n",
    "\n",
    "        rt_max : float\n",
    "            Controls the maximum rts that can be predicted.\n",
    "            Making this higher might make the function a bit slower.\n",
    "\n",
    "        dt : float\n",
    "            Controls the time resolution of the diffusion decision model. Default is 1 msec.\n",
    "            Lower values of dt make the function more precise but much slower.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        pp_rt : np.ndarray\n",
    "            Array of shape (n_samples, n_trials) containing predicted response times.\n",
    "\n",
    "        pp_acc : np.ndarray\n",
    "            Array of shape (n_samples, n_trials) containing predicted choices.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if n_posterior_predictives > self.parameters_info['n_posterior_samples']:\n",
    "            warnings.warn(\"Cannot have more posterior predictive samples than posterior samples. \" \\\n",
    "                          \"Will continue with n_posterior_predictives=%s\" % self.parameters_info['n_posterior_samples'],\n",
    "                          UserWarning,\n",
    "                          stacklevel=2)\n",
    "            n_posterior_predictives = self.parameters_info['n_posterior_samples']\n",
    "\n",
    "        drift_t = trial_samples['drift_t'][:n_posterior_predictives, :]\n",
    "        threshold_t = trial_samples['threshold_t'][:n_posterior_predictives, :]\n",
    "        ndt_t = trial_samples['ndt_t'][:n_posterior_predictives, :]\n",
    "\n",
    "        if starting_point_bias:\n",
    "            rel_sp_t = trial_samples['rel_sp_t'][:n_posterior_predictives, :]\n",
    "            pp_rt, pp_acc = random_ddm(drift_t, threshold_t, ndt_t, rel_sp=rel_sp_t, **kwargs)\n",
    "        else:\n",
    "            pp_rt, pp_acc = random_ddm(drift_t, threshold_t, ndt_t, rel_sp=.5, **kwargs)\n",
    "        return pp_rt, pp_acc\n",
    "\n",
    "    def get_posterior_predictives_df(self, n_posterior_predictives=500, **kwargs):\n",
    "        \"\"\"Calculates posterior predictives of choices and response times.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        n_posterior_predictives : int\n",
    "             Number of posterior samples to use for posterior predictives calculation.\n",
    "             If n_posterior_predictives is bigger than the posterior samples,\n",
    "             then calculation will continue with the total number of posterior samples.\n",
    "\n",
    "        Other Parameters\n",
    "        ----------------\n",
    "\n",
    "        noise_constant : float\n",
    "            Scaling factor of the diffusion decision model.\n",
    "            If changed, drift and threshold would be scaled accordingly.\n",
    "            Not to be changed in most applications.\n",
    "\n",
    "        rt_max : float\n",
    "            Controls the maximum rts that can be predicted.\n",
    "            Making this higher might make the function a bit slower.\n",
    "\n",
    "        dt : float\n",
    "            Controls the time resolution of the diffusion decision model. Default is 1 msec.\n",
    "            Lower values of dt make the function more precise but much slower.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        out : DataFrame\n",
    "            Data frame of shape (n_samples, n_trials*2).\n",
    "            Response times and accuracy are provided as hierarchical column indeces.\n",
    "\n",
    "        \"\"\"\n",
    "        pp_rt, pp_acc = get_posterior_predictives(self,n_posterior_predictives, **kwargs)\n",
    "\n",
    "        tmp1 = pd.DataFrame(pp_rt,\n",
    "                            index=pd.Index(np.arange(1, len(pp_rt)+1), name='sample'),\n",
    "                            columns=pd.MultiIndex.from_product((['rt'],\n",
    "                                                                np.arange(pp_rt.shape[1])+1),\n",
    "                                                               names=['variable', 'trial']))\n",
    "        tmp2 = pd.DataFrame(pp_acc,\n",
    "                            index=pd.Index(np.arange(1, len(pp_acc)+1), name='sample'),\n",
    "                            columns=pd.MultiIndex.from_product((['accuracy'],\n",
    "                                                                np.arange(pp_acc.shape[1])+1),\n",
    "                                                               names=['variable', 'trial']))\n",
    "        out = pd.concat((tmp1, tmp2), axis=1)\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def get_posterior_predictives_summary(self,\n",
    "                                          n_posterior_predictives=500,\n",
    "                                          quantiles=None,\n",
    "                                          **kwargs):\n",
    "        \"\"\"Calculates summary of posterior predictives of choices and response times.\n",
    "\n",
    "        The mean proportion of choices (in this case coded as accuracy) is calculated\n",
    "        for each posterior sample across all trials.\n",
    "        Response times are summarized using mean, skewness, and quantiles.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        n_posterior_predictives : int\n",
    "             Number of posterior samples to use for posterior predictives calculation.\n",
    "             If n_posterior_predictives is bigger than the posterior samples,\n",
    "             then calculation will continue with the total number of posterior samples.\n",
    "\n",
    "        quantiles : list of floats\n",
    "             Quantiles to summarize response times distributions\n",
    "             (separately for correct/incorrect) with.\n",
    "             Default to [.1, .3, .5, .7, .9].\n",
    "\n",
    "        Other Parameters\n",
    "        ----------------\n",
    "\n",
    "        noise_constant : float\n",
    "            Scaling factor of the diffusion decision model.\n",
    "            If changed, drift and threshold would be scaled accordingly.\n",
    "            Not to be changed in most applications.\n",
    "\n",
    "        rt_max : float\n",
    "            Controls the maximum rts that can be predicted.\n",
    "            Making this higher might make the function a bit slower.\n",
    "\n",
    "        dt : float\n",
    "            Controls the time resolution of the diffusion decision model. Default is 1 msec.\n",
    "            Lower values of dt make the function more precise but much slower.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        out : DataFrame\n",
    "            Pandas DataFrame, where every row corresponds to a posterior sample.\n",
    "            The columns contains the mean accuracy for each posterior sample,\n",
    "            as well as mean response times, response times skewness and response times quantiles.\n",
    "\n",
    "        \"\"\"\n",
    "        if quantiles is None:\n",
    "            quantiles = [.1, .3, .5, .7, .9]\n",
    "\n",
    "        pp = get_posterior_predictives_df(self,\n",
    "            n_posterior_predictives=n_posterior_predictives,\n",
    "            **kwargs)\n",
    "\n",
    "        tmp = pd.DataFrame({'mean_accuracy': pp['accuracy'].mean(axis=1),\n",
    "                            'mean_rt': pp['rt'].mean(axis=1),\n",
    "                            'skewness': pp['rt'].skew(axis=1, skipna=True)})\n",
    "\n",
    "        pp_rt_low = pp['rt'][pp['accuracy'] == 0] # lower boundary (usually incorrect)\n",
    "        pp_rt_up = pp['rt'][pp['accuracy'] == 1] # upper boundary (usually correct)\n",
    "\n",
    "        q_low = pp_rt_low.quantile(q=quantiles, axis=1).T\n",
    "        q_up = pp_rt_up.quantile(q=quantiles, axis=1).T\n",
    "\n",
    "        q_low.columns = ['quant_{}_rt_low'.format(int(c*100)) for c in q_low.columns]\n",
    "        q_up.columns = ['quant_{}_rt_up'.format(int(c*100)) for c in q_up.columns]\n",
    "\n",
    "        out = pd.concat([tmp, q_low, q_up], axis=1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.92475994, 0.86375994, 0.30575994, ..., 0.31615807, 0.60715807,\n",
       "         0.68115807],\n",
       "        [1.27986898, 0.76886898, 0.65386898, ..., 0.45406389, 0.47806389,\n",
       "         0.56606389],\n",
       "        [1.57506216, 0.42606216, 0.60906216, ..., 0.51636242, 0.47736242,\n",
       "         0.37336242],\n",
       "        ...,\n",
       "        [0.88593212, 0.45093212, 0.45193212, ..., 0.58068832, 0.34968832,\n",
       "         0.52168832],\n",
       "        [0.83584109, 0.87284109, 1.06684109, ..., 0.30822087, 0.34822087,\n",
       "         0.43722087],\n",
       "        [0.40912721, 0.82112721, 0.42712721, ..., 0.6475516 , 0.6165516 ,\n",
       "         0.8485516 ]]),\n",
       " array([[0., 1., 1., ..., 1., 0., 1.],\n",
       "        [0., 1., 1., ..., 0., 0., 1.],\n",
       "        [1., 1., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 0., 0., ..., 1., 0., 1.],\n",
       "        [0., 1., 1., ..., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_posterior_predictives(fits_DDM.DDMFittedModel, n_posterior_predictives=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_df = get_posterior_predictives_summary(fits_DDM.DDMFittedModel,n_posterior_predictives=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def plot_mean_posterior_predictives(self,\n",
    "                                        n_posterior_predictives,\n",
    "                                        figsize=(20, 8),\n",
    "                                        post_pred_kws=None,\n",
    "                                        **kwargs):\n",
    "        \"\"\"Plots the mean posterior predictives of choices and response times.\n",
    "\n",
    "        The mean proportion of choices (in this case coded as accuracy) is calculated\n",
    "        for each posterior sample across all trials,\n",
    "        and then it's plotted as a distribution.\n",
    "        The mean accuracy in the data is plotted as vertical line.\n",
    "        This allows to compare the real mean with the BCI or HDI of the predictions.\n",
    "        The same is done for response times, and are plotted one next to each other.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        n_posterior_predictives : int\n",
    "             Number of posterior samples to use for posterior predictives calculation.\n",
    "             If n_posterior_predictives is bigger than the posterior samples,\n",
    "             then calculation will continue with the total number of posterior samples.\n",
    "\n",
    "        figsize : tuple\n",
    "            figure size of the matplotlib figure\n",
    "\n",
    "        Other Parameters\n",
    "        ----------------\n",
    "\n",
    "        show_data : bool\n",
    "            Whether to show a vertical line for the mean data. Set to False to not show it.\n",
    "\n",
    "        color : matplotlib color\n",
    "            Color for both the mean data and intervals.\n",
    "\n",
    "        ax : matplotlib axis, optional\n",
    "            If provided, plot on this axis.\n",
    "            Default is set to current Axes.\n",
    "\n",
    "        gridsize : int\n",
    "            Resolution of the kernel density estimation function, default to 100.\n",
    "\n",
    "        clip : tuple\n",
    "            Range for the kernel density estimation function.\n",
    "            Default is min and max values of the distribution.\n",
    "\n",
    "        show_intervals : either \"HDI\", \"BCI\", or None\n",
    "            HDI is better when the distribution is not simmetrical.\n",
    "            If None, then no intervals are shown.\n",
    "\n",
    "        alpha_intervals : float\n",
    "            Alpha level for the intervals.\n",
    "            Default is 5 percent which gives 95 percent BCIs and HDIs.\n",
    "\n",
    "        intervals_kws : dictionary\n",
    "            Additional arguments for the matplotlib fill_between function\n",
    "            that shows shaded intervals.\n",
    "            By default, they are 50 percent transparent.\n",
    "\n",
    "        post_pred_kws : dictionary\n",
    "            Additional parameters to get_posterior_predictives_summary.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        fig : matplotlib.figure.Figure\n",
    "\n",
    "        \"\"\"\n",
    "        if post_pred_kws is None:\n",
    "            post_pred_kws = {}\n",
    "\n",
    "        pp_df = self.get_posterior_predictives_summary(n_posterior_predictives, **post_pred_kws)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "        plotting.plot_mean_prediction(pp_df,\n",
    "                                      self.data_info['data'],\n",
    "                                      y_data='accuracy',\n",
    "                                      y_predictions='mean_accuracy',\n",
    "                                      ax=axes[0],\n",
    "                                      **kwargs)\n",
    "\n",
    "        plotting.plot_mean_prediction(pp_df,\n",
    "                                      self.data_info['data'],\n",
    "                                      y_data='rt',\n",
    "                                      y_predictions='mean_rt',\n",
    "                                      ax=axes[1],\n",
    "                                      **kwargs)\n",
    "\n",
    "        axes[0].set_xlabel('Mean accuracy')\n",
    "        axes[1].set_xlabel('Mean RTs')\n",
    "        axes[0].set_ylabel('Density')\n",
    "        sns.despine()\n",
    "        return fig\n",
    "\n",
    "    def plot_quantiles_posterior_predictives(self,\n",
    "                                             n_posterior_predictives,\n",
    "                                             quantiles=None,\n",
    "                                             figsize=(20, 8),\n",
    "                                             post_pred_kws=None,\n",
    "                                             **kwargs):\n",
    "        \"\"\"Plots the quantiles of the posterior predictives of response times,\n",
    "        separately for correct/incorrect responses.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        n_posterior_predictives : int\n",
    "             Number of posterior samples to use for posterior predictives calculation.\n",
    "             If n_posterior_predictives is bigger than the posterior samples,\n",
    "             then calculation will continue with the total number of posterior samples.\n",
    "\n",
    "        quantiles : list of floats\n",
    "             Quantiles to summarize response times distributions\n",
    "             (separately for correct/incorrect) with.\n",
    "\n",
    "        figsize : tuple\n",
    "            figure size of the matplotlib figure\n",
    "\n",
    "        Other Parameters\n",
    "        ----------------\n",
    "\n",
    "        show_data : bool\n",
    "            Whether to show the quantiles of the data. Set to False to not show it.\n",
    "\n",
    "        show_intervals : either \"HDI\", \"BCI\", or None\n",
    "            HDI is better when the distribution is not simmetrical.\n",
    "            If None, then no intervals are shown.\n",
    "\n",
    "        alpha_intervals : float\n",
    "            Alpha level for the intervals.\n",
    "            Default is 5 percent which gives 95 percent BCIs and HDIs.\n",
    "\n",
    "        kind : either 'lines' or 'shades'\n",
    "            Two different styles to plot quantile distributions.\n",
    "\n",
    "        color : matplotlib color\n",
    "            Color for both the data and intervals.\n",
    "\n",
    "        scatter_kws : dictionary\n",
    "            Additional plotting parameters to change how the data points are shown.\n",
    "\n",
    "        intervals_kws : dictionary\n",
    "            Additional plotting parameters to change how the quantile distributions are shown.\n",
    "\n",
    "        post_pred_kws : dictionary\n",
    "            Additional parameters to get_posterior_predictives_summary.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        fig : matplotlib.figure.Figure\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if post_pred_kws is None:\n",
    "            post_pred_kws = {}\n",
    "\n",
    "        pp_summary = self.get_posterior_predictives_summary(\n",
    "            n_posterior_predictives=n_posterior_predictives,\n",
    "            quantiles=quantiles,\n",
    "            **post_pred_kws)\n",
    "\n",
    "        fig = plotting.plot_quantiles_prediction(pp_summary,\n",
    "                                                 self.data_info['data'],\n",
    "                                                 'ddm',\n",
    "                                                 quantiles=quantiles,\n",
    "                                                 figsize=figsize,\n",
    "                                                 **kwargs)\n",
    "        return fig\n",
    "\n",
    "    def get_grouped_posterior_predictives_summary(self,\n",
    "                                                  grouping_vars,\n",
    "                                                  n_posterior_predictives=500,\n",
    "                                                  quantiles=None,\n",
    "                                                  **kwargs):\n",
    "        \"\"\"Calculates summary of posterior predictives of choices and response times,\n",
    "        separately for a list of grouping variables.\n",
    "\n",
    "        The mean proportion of choices (in this case coded as accuracy) is calculated\n",
    "        for each posterior sample across all trials\n",
    "        in all conditions combination.\n",
    "        Response times are summarized using mean, skewness, and quantiles.\n",
    "\n",
    "        For example, if grouping_vars=['reward', 'difficulty'],\n",
    "        posterior predictives will be collapsed\n",
    "        for all combinations of levels of the reward and difficulty variables.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        grouping_vars :  list of strings\n",
    "             They should be existing grouping variables in the data.\n",
    "\n",
    "        n_posterior_predictives : int\n",
    "             Number of posterior samples to use for posterior predictives calculation.\n",
    "             If n_posterior_predictives is bigger than the posterior samples,\n",
    "             then calculation will continue with the total number of posterior samples.\n",
    "\n",
    "        quantiles : list of floats\n",
    "             Quantiles to summarize response times distributions\n",
    "             (separately for correct/incorrect) with.\n",
    "\n",
    "        Other Parameters\n",
    "        ----------------\n",
    "\n",
    "        noise_constant : float\n",
    "            Scaling factor of the diffusion decision model.\n",
    "            If changed, drift and threshold would be scaled accordingly.\n",
    "            Not to be changed in most applications.\n",
    "\n",
    "        rt_max : float\n",
    "            Controls the maximum rts that can be predicted.\n",
    "            Making this higher might make the function a bit slower.\n",
    "\n",
    "        dt : float\n",
    "            Controls the time resolution of the diffusion decision model. Default is 1 msec.\n",
    "            Lower values of dt make the function more precise but much slower.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        out : DataFrame\n",
    "             Pandas DataFrame.\n",
    "             The columns contains the mean accuracy for each posterior sample,\n",
    "             as well as mean response times, response times skewness and response times quantiles.\n",
    "             The row index is a pandas.MultIndex, with the grouping variables as higher level\n",
    "             and number of samples as lower level.\n",
    "\n",
    "        \"\"\"\n",
    "        if quantiles is None:\n",
    "            quantiles = [.1, .3, .5, .7, .9]\n",
    "\n",
    "        data_copy = self.data_info['data'].copy()\n",
    "        data_copy['trial'] = np.arange(1, self.data_info['N']+ 1)\n",
    "        data_copy.set_index('trial', inplace=True)\n",
    "\n",
    "        pp = self.get_posterior_predictives_df(n_posterior_predictives=n_posterior_predictives,\n",
    "                                               **kwargs)\n",
    "\n",
    "        tmp = pp.copy().T.reset_index().set_index('trial')\n",
    "\n",
    "        tmp = pd.merge(tmp,\n",
    "                       data_copy[grouping_vars],\n",
    "                       left_index=True,\n",
    "                       right_index=True).reset_index()\n",
    "        tmp_rt = tmp[tmp.variable == 'rt'].drop('variable', axis=1)\n",
    "        tmp_accuracy = tmp[tmp.variable == 'accuracy'].drop('variable', axis=1)\n",
    "\n",
    "        out = pd.concat([tmp_accuracy.groupby(grouping_vars).mean().drop('trial',\n",
    "                                                                         axis=1).stack().to_frame('mean_accuracy'),\n",
    "                         tmp_rt.groupby(grouping_vars).mean().drop('trial',\n",
    "                                                                   axis=1).stack().to_frame('mean_rt'),\n",
    "                         tmp_rt.groupby(grouping_vars).skew().drop('trial',\n",
    "                                                                   axis=1).stack().to_frame('skewness')],\n",
    "                        axis=1)\n",
    "\n",
    "        tmp_accuracy.set_index(list(np.append(grouping_vars, 'trial')), inplace=True)\n",
    "        tmp_rt.set_index(list(np.append(grouping_vars, 'trial')), inplace=True)\n",
    "\n",
    "        pp_rt_low = tmp_rt[tmp_accuracy == 0] # lower boundary (usually incorrect)\n",
    "        pp_rt_up = tmp_rt[tmp_accuracy == 1] # upper boundary (usually correct)\n",
    "\n",
    "        for q in quantiles:\n",
    "            new_col = 'quant_{}_rt_low'.format(int(q*100))\n",
    "\n",
    "            out[new_col] = pp_rt_low.reset_index().groupby(grouping_vars).quantile(q).drop('trial',\n",
    "                                                                                           axis=1).stack().to_frame('quant')\n",
    "\n",
    "            new_col = 'quant_{}_rt_up'.format(int(q*100))\n",
    "\n",
    "            out[new_col] = pp_rt_up.reset_index().groupby(grouping_vars).quantile(q).drop('trial',\n",
    "                                                                                          axis=1).stack().to_frame('quant')\n",
    "\n",
    "        out.index.rename(np.append(grouping_vars, 'sample'), inplace=True)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def plot_mean_grouped_posterior_predictives(self,\n",
    "                                                grouping_vars,\n",
    "                                                n_posterior_predictives,\n",
    "                                                figsize=(20, 8),\n",
    "                                                post_pred_kws=None,\n",
    "                                                **kwargs):\n",
    "        \"\"\"Plots the mean posterior predictives of choices and response times,\n",
    "        separately for either 1 or 2 grouping variables.\n",
    "\n",
    "        The first grouping variable will be plotted on the x-axis.\n",
    "        The second grouping variable, if provided, will be showed\n",
    "        with a different color per variable level.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        grouping_vars :  list of strings\n",
    "             They should be existing grouping variables in the data.\n",
    "             The list should be of lenght 1 or 2.\n",
    "\n",
    "        n_posterior_predictives : int\n",
    "             Number of posterior samples to use for posterior predictives calculation.\n",
    "             If n_posterior_predictives is bigger than the posterior samples,\n",
    "             then calculation will continue with the total number of posterior samples.\n",
    "\n",
    "        Other Parameters\n",
    "        ----------------\n",
    "\n",
    "        x_order : list of strings\n",
    "            Order to plot the levels of the first grouping variable in,\n",
    "            otherwise the levels are inferred from the data objects.\n",
    "\n",
    "        hue_order : lists of strings\n",
    "            Order to plot the levels of the second grouping variable (when provided) in,\n",
    "            otherwise the levels are inferred from the data objects.\n",
    "\n",
    "        hue_labels : list of strings\n",
    "            Labels corresponding to hue_order in the legend.\n",
    "            Advised to specify hue_order when using this to avoid confusion.\n",
    "            Only makes sense when the second grouping variable is provided.\n",
    "\n",
    "        show_data : bool\n",
    "            Whether to show a vertical line for the mean data. Set to False to not show it.\n",
    "\n",
    "        show_intervals : either \"HDI\", \"BCI\", or None\n",
    "            HDI is better when the distribution is not simmetrical.\n",
    "            If None, then no intervals are shown.\n",
    "\n",
    "        alpha_intervals : float\n",
    "            Alpha level for the intervals.\n",
    "            Default is 5 percent which gives 95 percent BCIs and HDIs.\n",
    "\n",
    "        palette : palette name, list, or dict\n",
    "            Colors to use for the different levels of the second grouping variable (when provided).\n",
    "            Should be something that can be interpreted by color_palette(),\n",
    "            or a dictionary mapping hue levels to matplotlib colors.\n",
    "\n",
    "        color : matplotlib color\n",
    "            Color for both the mean data and intervals.\n",
    "            Only used when there is 1 grouping variable.\n",
    "\n",
    "        ax : matplotlib axis, optional\n",
    "            If provided, plot on this axis.\n",
    "            Default is set to current Axes.\n",
    "\n",
    "        intervals_kws : dictionary\n",
    "            Additional arguments for the matplotlib fill_between function\n",
    "            that shows shaded intervals.\n",
    "            By default, they are 50 percent transparent.\n",
    "\n",
    "         post_pred_kws : dictionary\n",
    "             Additional parameters to get_grouped_posterior_predictives_summary.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        fig : matplotlib.figure.Figure\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if np.sum(len(grouping_vars) == np.array([1, 2])) < 1:\n",
    "            raise ValueError(\"must be a list of either 1 or values\")\n",
    "\n",
    "        if post_pred_kws is None:\n",
    "            post_pred_kws = {}\n",
    "\n",
    "        pp = self.get_grouped_posterior_predictives_summary(grouping_vars,\n",
    "                                                            n_posterior_predictives,\n",
    "                                                            **post_pred_kws)\n",
    "\n",
    "        if len(grouping_vars) == 1:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "            plotting.plot_grouped_mean_prediction(x=grouping_vars[0],\n",
    "                                                  y_data='accuracy',\n",
    "                                                  y_predictions='mean_accuracy',\n",
    "                                                  predictions=pp,\n",
    "                                                  data=self.data_info['data'],\n",
    "                                                  ax=axes[0],\n",
    "                                                  **kwargs)\n",
    "\n",
    "            plotting.plot_grouped_mean_prediction(x=grouping_vars[0],\n",
    "                                                  y_data='rt',\n",
    "                                                  y_predictions='mean_rt',\n",
    "                                                  predictions=pp,\n",
    "                                                  data=self.data_info['data'],\n",
    "                                                  ax=axes[1],\n",
    "                                                  **kwargs)\n",
    "        else:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "            plotting.plot_grouped_mean_prediction(x=grouping_vars[0],\n",
    "                                                  y_data='accuracy',\n",
    "                                                  y_predictions='mean_accuracy',\n",
    "                                                  predictions=pp,\n",
    "                                                  data=self.data_info['data'],\n",
    "                                                  hue=grouping_vars[1],\n",
    "                                                  ax=axes[0],\n",
    "                                                  **kwargs)\n",
    "\n",
    "            plotting.plot_grouped_mean_prediction(x=grouping_vars[0],\n",
    "                                                  y_data='rt',\n",
    "                                                  y_predictions='mean_rt',\n",
    "                                                  predictions=pp,\n",
    "                                                  data=self.data_info['data'],\n",
    "                                                  hue=grouping_vars[1],\n",
    "                                                  ax=axes[1],\n",
    "                                                  **kwargs)\n",
    "            axes[0].get_legend().remove()\n",
    "            axes[1].legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "        axes[0].set_ylabel('Mean accuracy')\n",
    "        axes[1].set_ylabel('Mean RTs')\n",
    "\n",
    "        sns.despine()\n",
    "        return fig\n",
    "\n",
    "    def plot_quantiles_grouped_posterior_predictives(self,\n",
    "                                                     n_posterior_predictives,\n",
    "                                                     grouping_var,\n",
    "                                                     quantiles=None,\n",
    "                                                     figsize=(20, 8),\n",
    "                                                     post_pred_kws=None,\n",
    "                                                     **kwargs):\n",
    "        \"\"\"Plots the quantiles of the posterior predictives of response times,\n",
    "        separately for correct/incorrect responses, and 1 grouping variable.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        n_posterior_predictives : int\n",
    "             Number of posterior samples to use for posterior predictives calculation.\n",
    "             If n_posterior_predictives is bigger than the posterior samples,\n",
    "             then calculation will continue with the total number of posterior samples.\n",
    "\n",
    "        grouping_vars :  string\n",
    "             Should be an existing grouping variable in the data.\n",
    "\n",
    "        quantiles : list of floats\n",
    "             Quantiles to summarize response times distributions\n",
    "             (separately for correct/incorrect) with.\n",
    "\n",
    "        figsize : tuple\n",
    "            figure size of the matplotlib figure\n",
    "\n",
    "        Other Parameters\n",
    "        ----------------\n",
    "\n",
    "        show_data : bool\n",
    "            Whether to show the quantiles of the data. Set to False to not show it.\n",
    "\n",
    "        show_intervals : either \"HDI\", \"BCI\", or None\n",
    "            HDI is better when the distribution is not simmetrical.\n",
    "            If None, then no intervals are shown.\n",
    "\n",
    "        alpha_intervals : float\n",
    "            Alpha level for the intervals.\n",
    "            Default is 5 percent which gives 95 percent BCIs and HDIs.\n",
    "\n",
    "        kind : either 'lines' or 'shades'\n",
    "            Two different styles to plot quantile distributions.\n",
    "\n",
    "        palette : palette name, list, or dict\n",
    "            Colors to use for the different levels of the second grouping variable (when provided).\n",
    "            Should be something that can be interpreted by color_palette(),\n",
    "            or a dictionary mapping hue levels to matplotlib colors.\n",
    "\n",
    "        hue_order : lists of strings\n",
    "            Order to plot the levels of the grouping variable in,\n",
    "            otherwise the levels are inferred from the data objects.\n",
    "\n",
    "        hue_labels : list of strings\n",
    "            Labels corresponding to hue_order in the legend.\n",
    "            Advised to specify hue_order when using this to avoid confusion.\n",
    "\n",
    "        jitter: float\n",
    "            Amount to jitter the grouping variable's levels for better visualization.\n",
    "\n",
    "        scatter_kws : dictionary\n",
    "            Additional plotting parameters to change how the data points are shown.\n",
    "\n",
    "        intervals_kws : dictionary\n",
    "            Additional plotting parameters to change how the quantile distributions are shown.\n",
    "\n",
    "        post_pred_kws : dictionary\n",
    "            Additional parameters to get_grouped_posterior_predictives_summary.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        fig : matplotlib.figure.Figure\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if post_pred_kws is None:\n",
    "            post_pred_kws = {}\n",
    "\n",
    "        pp_summary = self.get_grouped_posterior_predictives_summary(\n",
    "            n_posterior_predictives=n_posterior_predictives,\n",
    "            grouping_vars=[grouping_var],\n",
    "            quantiles=quantiles,\n",
    "            **post_pred_kws)\n",
    "\n",
    "        fig = plotting.plot_grouped_quantiles_prediction(pp_summary,\n",
    "                                                         self.data_info['data'],\n",
    "                                                         'ddm',\n",
    "                                                         quantiles=quantiles,\n",
    "                                                         grouping_var=grouping_var,\n",
    "                                                         figsize=figsize,\n",
    "                                                         **kwargs)\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting ^_^ happy plotting ^_^ happy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting mean_posterior_predictives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from rlssm import plotting\n",
    "figsize=(20, 8)\n",
    "post_pred_kws=None\n",
    "n_posterior_predictives = 500\n",
    "if post_pred_kws is None:\n",
    "    post_pred_kws = {}\n",
    "    pp_df = get_posterior_predictives_summary(fits_DDM.DDMFittedModel,n_posterior_predictives, **post_pred_kws)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    plotting.plot_mean_prediction(pp_df,\n",
    "                                      fits_DDM.DDMFittedModel.data_info['data'],\n",
    "                                      y_data='accuracy',\n",
    "                                      y_predictions='mean_accuracy',\n",
    "                                      ax=axes[0])\n",
    "                                     # **kwargs)\n",
    "\n",
    "    plotting.plot_mean_prediction(pp_df,\n",
    "                                      fits_DDM.DDMFittedModel.data_info['data'],\n",
    "                                      y_data='rt',\n",
    "                                      y_predictions='mean_rt',\n",
    "                                      ax=axes[1])\n",
    "                                      #**kwargs)\n",
    "\n",
    "    axes[0].set_xlabel('Mean accuracy')\n",
    "    axes[1].set_xlabel('Mean RTs')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting quantiles_posterior_predictives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figsize=(20, 8)\n",
    "post_pred_kws=None   \n",
    "quantiles = [.1, .3, .5, .7, .9]\n",
    "n_posterior_predictives = 500\n",
    "\n",
    "if post_pred_kws is None:\n",
    "    post_pred_kws = {}\n",
    "\n",
    "pp_summary = get_posterior_predictives_summary(fits_DDM.DDMFittedModel,\n",
    "            n_posterior_predictives=n_posterior_predictives,\n",
    "            quantiles=quantiles,\n",
    "            **post_pred_kws)\n",
    "\n",
    "fig = plotting.plot_quantiles_prediction(pp_summary,\n",
    "                                                 fits_DDM.DDMFittedModel.data_info['data'],\n",
    "                                                 'ddm',\n",
    "                                                 quantiles=quantiles,\n",
    "                                                 figsize=figsize)\n",
    "                                                 #**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_grouped_posterior_predictives_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuanyan/opt/anaconda3/envs/RLDDM.stan/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"model_fit.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'model' : sm, 'fit' : fit}, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to open the results file\n",
    "#with open(\"model_fit.pkl\", \"rb\") as f:\n",
    " #   data_dict = pickle.load(f)\n",
    "    # or with a list\n",
    "    # data_list = pickle.load(f)\n",
    "#fit = data_dict['fit']\n",
    "# fit = data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-cfc11376c2e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresultsall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'fit'"
     ]
    }
   ],
   "source": [
    "resultsall=data_dict['fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-e9ba595b3198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# or with a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfitrrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open(\"model_fit.pkl\", \"rb\") as f:\n",
    "    data_dict = pickle.load(f)\n",
    "    # or with a list\n",
    "    data_list = pickle.load(f)\n",
    "\n",
    "fitrrr = data_dict['fit']\n",
    "# fit = data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Truncated summary with the 'fit.__repr__' method. For the full summary use 'print(fit)'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <pystan.model.StanModel at 0x7f833712a210>,\n",
       " 'fit': \n",
       " Warning: Shown data is truncated to 100 parameters\n",
       " For the full summary use 'print(fit)'\n",
       " \n",
       " Inference for Stan model: anon_model_bc4dd4dced0824789d173a170c757d92.\n",
       " 2 chains, each with iter=1000; warmup=500; thin=1; \n",
       " post-warmup draws per chain=500, total post-warmup draws=1000.\n",
       " \n",
       "                       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       " mu_alpha             -0.41  6.7e-3   0.11  -0.62  -0.48  -0.41  -0.34  -0.18    269    1.0\n",
       " mu_drift_scaling      2.44    0.03   0.41   1.68   2.16   2.43   2.71   3.27    147    1.0\n",
       " mu_threshold          0.93  4.7e-3   0.06    0.8   0.89   0.93   0.97   1.03    159    1.0\n",
       " mu_ndt               -1.23  5.7e-3   0.04  -1.31  -1.26  -1.24   -1.2  -1.14     57   1.03\n",
       " sd_alpha               0.5  2.1e-3   0.05   0.41   0.47    0.5   0.53    0.6    532    1.0\n",
       " sd_drift_scaling      1.94    0.02   0.34    1.4   1.71   1.91   2.14   2.66    254    1.0\n",
       " sd_threshold          0.29  2.7e-3   0.05   0.22   0.25   0.28   0.32   0.39    272   1.01\n",
       " sd_ndt                0.22  2.6e-3   0.03   0.16    0.2   0.21   0.24   0.29    155   1.01\n",
       " z_alpha[1]            2.27    0.02   0.53    1.3    1.9   2.25   2.62   3.37    835    1.0\n",
       " z_alpha[2]            1.36    0.02   0.52   0.39    1.0   1.34   1.68   2.46    643    1.0\n",
       " z_alpha[3]           -1.66    0.02   0.44  -2.47  -1.94  -1.65  -1.37  -0.75    696    1.0\n",
       " z_alpha[4]           -1.35    0.02   0.68  -2.58   -1.8   -1.4  -0.97   0.11    845    1.0\n",
       " z_alpha[5]            0.66    0.02   0.61   -0.6   0.29   0.68   1.05   1.85    912    1.0\n",
       " z_alpha[6]            1.45    0.02   0.48   0.54   1.14   1.44   1.76   2.42    722    1.0\n",
       " z_alpha[7]           -0.14    0.02   0.44  -1.05  -0.41  -0.14   0.14   0.73    747    1.0\n",
       " z_alpha[8]           -0.08    0.01    0.3  -0.67  -0.28  -0.07   0.13   0.51    440    1.0\n",
       " z_alpha[9]            1.23    0.02   0.55   0.18   0.86   1.24   1.59   2.37    798    1.0\n",
       " z_alpha[10]           2.28    0.02   0.53   1.31   1.92   2.26    2.6   3.48    782    1.0\n",
       " z_alpha[11]           -0.4    0.01   0.32  -1.01  -0.61   -0.4  -0.19   0.22    491    1.0\n",
       " z_alpha[12]           -0.6    0.05   1.12   -2.9  -1.31  -0.56   0.14   1.56    552    1.0\n",
       " z_alpha[13]           1.98    0.02   0.49    1.1   1.63   1.97   2.29   2.98    692    1.0\n",
       " z_alpha[14]           1.46    0.02   0.53   0.43   1.11   1.45   1.81   2.52    885    1.0\n",
       " z_alpha[15]           -1.6    0.02   0.31  -2.25  -1.81  -1.59  -1.39  -0.98    432    1.0\n",
       " z_alpha[16]          -0.44    0.02    0.3  -1.03  -0.63  -0.45  -0.25   0.18    404    1.0\n",
       " z_alpha[17]          -0.51    0.01   0.35  -1.24  -0.74  -0.49  -0.26   0.14    637    1.0\n",
       " z_alpha[18]           0.92    0.02   0.49   0.03   0.57    0.9   1.22    2.0    752    1.0\n",
       " z_alpha[19]          -1.42    0.02   0.46  -2.38  -1.72   -1.4  -1.11  -0.54    589    1.0\n",
       " z_alpha[20]           0.06    0.02   0.31  -0.53  -0.15   0.07   0.27   0.66    418    1.0\n",
       " z_alpha[21]           -1.7    0.02   0.36  -2.39  -1.94  -1.69  -1.44   -1.0    490    1.0\n",
       " z_alpha[22]           -0.2    0.02   0.29  -0.77  -0.39  -0.18 1.4e-3   0.36    343    1.0\n",
       " z_alpha[23]           1.04    0.02   0.56  -0.01   0.65   1.04   1.38   2.17    967    1.0\n",
       " z_alpha[24]           -1.5    0.02   0.44   -2.4  -1.78  -1.49  -1.19  -0.64    592    1.0\n",
       " z_alpha[25]          -1.37    0.02   0.31  -1.95  -1.57  -1.38  -1.17  -0.74    356    1.0\n",
       " z_alpha[26]          -1.41    0.02   0.33  -2.06  -1.62  -1.38  -1.19  -0.76    444    1.0\n",
       " z_drift_scaling[1]   -0.81    0.02   0.27  -1.36  -0.97   -0.8  -0.62  -0.28    129    1.0\n",
       " z_drift_scaling[2]   -0.73    0.02   0.28  -1.32  -0.92  -0.71  -0.53  -0.21    137    1.0\n",
       " z_drift_scaling[3]     0.1    0.02   0.35  -0.61  -0.15   0.12   0.35   0.75    408    1.0\n",
       " z_drift_scaling[4]   -0.82    0.03   0.37  -1.53  -1.08  -0.81  -0.57  -0.11    198    1.0\n",
       " z_drift_scaling[5]    -0.8    0.02   0.31  -1.45  -0.99  -0.78  -0.58  -0.26    158    1.0\n",
       " z_drift_scaling[6]   -0.48    0.02   0.26  -1.04  -0.64  -0.47  -0.31 2.5e-3    141    1.0\n",
       " z_drift_scaling[7]   -0.29    0.02   0.27  -0.82  -0.46  -0.28  -0.09   0.23    155    1.0\n",
       " z_drift_scaling[8]    0.52    0.02   0.27  -0.02   0.33   0.53   0.71   1.07    273    1.0\n",
       " z_drift_scaling[9]   -0.86    0.02    0.3   -1.5  -1.04  -0.85  -0.66  -0.31    162    1.0\n",
       " z_drift_scaling[10]  -0.64    0.02   0.26  -1.17  -0.82  -0.63  -0.45  -0.14    147    1.0\n",
       " z_drift_scaling[11]   0.36    0.02   0.28  -0.21   0.18   0.36   0.55   0.91    261    1.0\n",
       " z_drift_scaling[12]  -1.89    0.03   0.56  -3.09  -2.25  -1.85  -1.51  -0.83    356    1.0\n",
       " z_drift_scaling[13]  -0.56    0.02   0.27  -1.13  -0.75  -0.55  -0.37  -0.09    140    1.0\n",
       " z_drift_scaling[14]   -0.6    0.02   0.27  -1.16  -0.79   -0.6  -0.43  -0.08    162    1.0\n",
       " z_drift_scaling[15]   2.07    0.02   0.47   1.17   1.73   2.06   2.38   2.95    511    1.0\n",
       " z_drift_scaling[16]   0.23    0.02   0.26  -0.29   0.06   0.23   0.41   0.71    238    1.0\n",
       " z_drift_scaling[17]   1.16    0.02   0.36   0.53   0.91   1.15   1.39   1.91    477    1.0\n",
       " z_drift_scaling[18]  -0.65    0.02   0.28  -1.26  -0.85  -0.65  -0.44  -0.17    151    1.0\n",
       " z_drift_scaling[19]   0.72    0.02   0.41-4.1e-3   0.45   0.69   0.99   1.62    433    1.0\n",
       " z_drift_scaling[20]   0.57    0.02   0.28   0.03   0.38   0.55   0.77   1.13    293    1.0\n",
       " z_drift_scaling[21]   0.35    0.02   0.31  -0.24   0.12   0.35   0.56    1.0    248    1.0\n",
       " z_drift_scaling[22]   0.68    0.02   0.28   0.14   0.48   0.67   0.88   1.24    344    1.0\n",
       " z_drift_scaling[23]  -0.82    0.02    0.3  -1.45   -1.0  -0.81  -0.61  -0.29    177    1.0\n",
       " z_drift_scaling[24]   0.17    0.02   0.34  -0.47  -0.06   0.15   0.41   0.84    387    1.0\n",
       " z_drift_scaling[25]    1.7    0.02   0.42   0.93   1.39   1.68   1.97   2.58    495    1.0\n",
       " z_drift_scaling[26]   1.67    0.02   0.43   0.89   1.35   1.64   1.96   2.57    523    1.0\n",
       " z_threshold[1]        1.99    0.02   0.42   1.21   1.68   1.97   2.27   2.85    363    1.0\n",
       " z_threshold[2]        0.28    0.02    0.3  -0.29   0.07   0.27   0.47   0.88    292    1.0\n",
       " z_threshold[3]        0.55    0.02    0.3  -0.02   0.35   0.55   0.75   1.21    270    1.0\n",
       " z_threshold[4]         2.2    0.02   0.43   1.38    1.9   2.18   2.49   3.08    302    1.0\n",
       " z_threshold[5]        0.01    0.02   0.28  -0.57  -0.17   0.01   0.19   0.56    243    1.0\n",
       " z_threshold[6]        0.33    0.02   0.29  -0.21   0.13   0.32    0.5   0.92    301    1.0\n",
       " z_threshold[7]        0.69    0.02   0.32   0.14   0.46   0.67   0.89    1.4    310    1.0\n",
       " z_threshold[8]        0.23    0.02   0.33  -0.39 9.7e-3   0.22   0.45   0.92    315    1.0\n",
       " z_threshold[9]      3.4e-3    0.02   0.29  -0.53  -0.19  -0.02   0.18   0.63    271    1.0\n",
       " z_threshold[10]       0.45    0.02   0.32  -0.15   0.22   0.44   0.65   1.09    317    1.0\n",
       " z_threshold[11]      -0.21    0.02   0.29   -0.8   -0.4  -0.21  -0.01   0.35    263    1.0\n",
       " z_threshold[12]     2.8e-4    0.02   0.27   -0.5  -0.19-7.6e-3   0.18   0.56    241    1.0\n",
       " z_threshold[13]      -0.23    0.02   0.31  -0.82  -0.44  -0.25  -0.03   0.36    302    1.0\n",
       " z_threshold[14]      -0.76    0.02    0.3  -1.38  -0.96  -0.75  -0.57  -0.13    222    1.0\n",
       " z_threshold[15]       -1.5    0.02   0.35   -2.2  -1.74  -1.49  -1.26  -0.86    246    1.0\n",
       " z_threshold[16]       1.17    0.02   0.36   0.53   0.91   1.14   1.39   1.91    302    1.0\n",
       " z_threshold[17]      -1.91    0.03   0.38  -2.67  -2.16  -1.89  -1.62  -1.22    232   1.01\n",
       " z_threshold[18]      -0.21    0.02   0.27  -0.74  -0.37  -0.22  -0.03   0.31    244    1.0\n",
       " z_threshold[19]      -0.69    0.02   0.28  -1.25  -0.88  -0.68  -0.49  -0.18    257    1.0\n",
       " z_threshold[20]      -0.83    0.02    0.3  -1.44  -1.03  -0.83  -0.62  -0.22    238    1.0\n",
       " z_threshold[21]       0.79    0.02   0.33   0.22   0.55   0.77   0.98   1.51    314    1.0\n",
       " z_threshold[22]       0.12    0.02   0.29  -0.44  -0.08   0.11   0.31   0.73    333    1.0\n",
       " z_threshold[23]      -0.35    0.02   0.29  -0.93  -0.54  -0.35  -0.15   0.19    252    1.0\n",
       " z_threshold[24]      -0.35    0.02   0.29  -0.91  -0.55  -0.34  -0.16   0.19    245    1.0\n",
       " z_threshold[25]      -1.51    0.02   0.34  -2.18  -1.74  -1.49  -1.26  -0.89    231   1.01\n",
       " z_threshold[26]      -0.59    0.02   0.34  -1.24  -0.81  -0.58  -0.36   0.07    277    1.0\n",
       " z_ndt[1]              -0.6    0.02   0.33  -1.33   -0.8  -0.57  -0.37  -0.04    270   1.01\n",
       " z_ndt[2]              0.76    0.03   0.26   0.26   0.57   0.76   0.94   1.25     84   1.02\n",
       " z_ndt[3]              0.66    0.03   0.24   0.19    0.5   0.67   0.82   1.13     67   1.03\n",
       " z_ndt[4]             -0.67    0.02   0.27  -1.27  -0.86  -0.65  -0.47   -0.2    234   1.01\n",
       " z_ndt[5]              -0.6    0.02   0.24  -1.13  -0.75  -0.59  -0.42  -0.17    128   1.02\n",
       " z_ndt[6]              0.08    0.03   0.22  -0.36  -0.07   0.09   0.24    0.5     71   1.03\n",
       " z_ndt[7]              1.37    0.03   0.31   0.79   1.14   1.37   1.59   1.98     88   1.02\n",
       " z_ndt[8]              0.92    0.03   0.26   0.41   0.75   0.93    1.1   1.41     66   1.02\n",
       " z_ndt[9]             -0.36    0.02   0.24  -0.83  -0.53  -0.36  -0.19   0.08    108   1.02\n",
       " z_ndt[10]            -1.66    0.02   0.32  -2.33  -1.86  -1.65  -1.45  -1.03    229   1.01\n",
       " z_ndt[11]             0.35    0.03   0.23  -0.11    0.2   0.36   0.52   0.78     71   1.02\n",
       " z_ndt[12]            -2.44    0.03   0.39  -3.23  -2.69  -2.45  -2.18   -1.7    203   1.01\n",
       " z_ndt[13]              1.4    0.03   0.31    0.8   1.18   1.41   1.61   2.04     85   1.02\n",
       " lp__                -809.5    0.64   9.83 -829.3 -816.3 -809.5 -802.4 -790.8    233   1.01\n",
       " \n",
       " Samples were drawn using NUTS at Sat Apr 24 10:31:11 2021.\n",
       " For each parameter, n_eff is a crude measure of effective sample size,\n",
       " and Rhat is the potential scale reduction factor on split chains (at \n",
       " convergence, Rhat=1).}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-9db5bb226eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0marviz\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'arviz'"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "summary = az.summary(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
